"""
Swiss Army knife that can
Input: spreadsheet with rows being populations, columns being Allele types, see e.g. completeAFnet.csv in Data dir,
       which was generated by the scrape* scripts that scrape AlleleFrequencies.net
       Also expected: a dictionary file that translates population ids to human understandable pop. names
Output: Various results can be derived, most central: a phylogenetic tree
        But also the cleaned and extended spreadsheet is a usable result in its own right, as e.g. used in the script
        comprehensiveTree.py

Main class is PopulationTree, see individual method doc strings there

Assumptions:

wraps around Phylip tools: Nei Distance,..., assuming them being installed
can run my own implementation of Nei (1972) Distance

TODO: replace system calls (based on os module) with subprocess module
"""

import numpy as np
import pickle
import pandas as pd
import re
import os
from itertools import groupby
from collections import Counter

def pp(node): return ":".join(node)

# alleleFreqDicts[0]  [(('A*68', '02'), 0.014), ((u'B*07',), 0.248), ((u'DQA1*04', u'01'), 0.019) ...]
#phylipDir = "/Users/ahenschel/Applications/phylip-3.695/exe"
phylipDir = "/home/ahenschel/miniconda2/bin"
phylipDir = "/Users/ahenschel/Applications/miniconda3/bin"

def renameAllele(allele):
    if allele[:3] in {'DPA', 'DPB', 'DQA', 'DQB', 'DRB'}: #those genes have a number with it
        splitPt = 4
    else:
        splitPt = {True:3, False:1}[allele.startswith('D')]
    return allele[:splitPt] + '*' + allele[splitPt:]

class AlleleFreqDict:
    """for a population, continas allele frequencies as a dict with the key as tuple like so:
                  ('A*74',): 0.011,
             ('A*80', '01'): 0.005,
             ('B*07', '02'): 0.063,
             ('B*08', '01'): 0.074,
        so possibly mixed resolution(!), whatever it gets from AlleleFrequencies.net

     """
    def __init__(self, alleleFreqDict, pop):
        self.afs = alleleFreqDict
        del self.afs['PopSize']
        ## construct graph
        self.pop = pop
        self.popSize = alleleFreqDict.get('PopSize', -1)
        self.inconsistencies = []
    def resolutionStats(self):
        return Counter([len(k) for k in self.afs.keys()])
    def alleleNamesToGraph(self):
        """creates a little tree structure for subtypes to all resolutions.
        Sounds a bit overkill, but can be useful later and is needed for inconsistency check, see below"""
        import networkx as nx

        self.G = nx.DiGraph()
        for key, value in sorted(self.afs.items()):
            path = [key[:i] for i in range(len(key) + 1)]
            self.G.add_path(path)
            self.G.node[key]['value'] = value

    def checkSubtypes(self, node):
        """given the tree structure of subtypes, checks for all possible inconsistencies between subtypes and
        their respective supertype: e.g. if A*01:01 is 20%, A*01:02 is 90% """

        children = self.G.successors(node)
        if children:
            subtypesum = sum([self.checkSubtypes(child) for child in children])
            if 'value' in self.G.node[node]:
                if not np.isclose(subtypesum, self.G.node[node]['value']) and node[0][0] in "ABC":
                    self.inconsistencies.append(
                        [pp(node), self.G.node[node]['value'], subtypesum, "+".join([pp(n) for n in self.G.successors(node)])])
            return subtypesum
        else:
            return self.G.node[node]['value']  ## assuming that every leaf has a value


class PopulationTree:
    def __init__(self, data="../Data/completeAFnet.csv", handSelection=False, precalc=False):
        """creates a dataframe from a csv file"""
        if precalc: return
        ## Loading data
        df = pd.read_csv(data, index_col=[0])
        if handSelection:
            #beduinData = pd.read_csv("../Data/beduinsAlleleFrequencies2.txt", index_col=[0])
            #beduinData['Selection'] = ['X']
            #beduinData['PopName'] = ['Beduin UAE']
            #beduinData['PopSize'] = [143]
            uae = pd.read_csv("../Data/uae_updatedAFs.csv", index_col=[0])
            uae['Selection'] = ['X']
            uae['PopName'] = ['UAE']
            #iraqi['PopName'] = ['Iraqi Abbas et al']
            uae['PopSize'] = [95]
            uae['A'] = uae['B'] = uae['C'] = 1.0
            #pdb.set_trace()
            self.df = pd.concat([df, uae], sort=True) ## avoids a warning
            self.df = self.df.reindex(df.columns, axis=1) ## concat scrambles columns :(
            #self.df = self.df.reindex_axis(df.columns, axis=1) ## deprecated

            self.df = self.df.fillna(0)
            #pdb.set_trace()

        else:
            self.popInfo = pd.read_csv("../Data/popInfo.csv", index_col=[0])
            with open("../Data/alleleFreqDicts.pcl", 'rb') as f:
                afs = pickle.load(f)
            with open("../Data/popListAFnet.pcl", 'rb') as f:
                self.popList = pickle.load(f)
            self.alleleFreqDicts  = [AlleleFreqDict(af, pop) for af, pop in zip(afs, self.popList)]

            # merge with our data (possibly other tables as well)
            #beduinData = pd.read_csv("../Data/uae_updatedAFs.csv", index_col=[0])
            #beduinData['PopSize'] = 95
            #beduinData['PopName'] = 'UAE KU'
            #beduinData = bd.drop(bd.columns[1:], axis=1).T  ## Warning, Windows format
            #b25 = pd.read_csv("../Data/beduins25c.csv", index_col=[0])
            #iraqi = pd.read_csv("../Data/iraqiHLA.csv", index_col=[0])

            #df = pd.concat([df, iraqi, beduinData], sort=True)
            df.fillna(0, inplace=True)

            self.df = pd.concat([df, self.popInfo], axis=1)

    def fix(self):
        """Renaming columns, calculating accumulated percentages/gene"""
        cols = self.df.columns.values
        lastIdx = list(cols).index('DRB116') + 1
        starNames = [renameAllele(c) for c in cols[:lastIdx]]
        self.df.columns = starNames + list(cols[lastIdx:])

        l = [n.split('*')[0] for n in starNames]
        l1 = l[::-1]
        self.genes = sorted(list(set(l)))
        self.geneCols = [(gene, (l.index(gene), len(l)-l1.index(gene))) for gene in self.genes] ## replaces self.groupings
        [('A', (0, 24)), ('B', (24, 65)), ('C', (65, 79)), ...] ## fixed problem with DRB1 etc
        for gene, (startCol, endCol) in self.geneCols:
            self.df['sum_%s'%gene] = self.df.iloc[:, startCol:endCol].sum(axis=1)  # quick and dirty, do it neat eventually
    def exploreGoodCombinations(self, nrGenes=2, thresh=.95, minPopSize=None):
        from itertools import combinations
        d = self.df
        if minPopSize: d = d[d.PopSize >= minPopSize] ## hasnt been considered in current stats
        ## just 2 genes selected:
        sumCols = ['sum_%s'%gene for gene in self.genes]
        ## super ugly, can't care right now
        if nrGenes==2:
            return sorted([(len(d[(d[g1] > thresh) & (d[g2] > thresh)]), g1, g2) for (g1,g2) in combinations(sumCols, 2)])
        if nrGenes==3:
            return sorted([(len(d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh)]), g1, g2, g3) for (g1,g2,g3) in combinations(sumCols, 3)])
        if nrGenes==4:
            return sorted([(len(d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh) & (d[g4] > thresh)]), g1, g2, g3, g4) for (g1,g2,g3,g4) in combinations(sumCols, 4)])
        if nrGenes==5:
            return sorted([(len(d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh) & (d[g4] > thresh) & (d[g5] > thresh)]), g1, g2, g3, g4, g5) for (g1,g2,g3,g4,g5) in combinations(sumCols, 5)])
        if nrGenes==6:
            return sorted([(len(d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh) & (d[g4] > thresh) & (d[g5] > thresh)& (d[g6] > thresh)]), g1, g2, g3, g4, g5, g6) for (g1,g2,g3,g4,g5,g6) in combinations(sumCols, 6)])

        #ptree.df[(ptree.df['sum_A']>0.95) & (ptree.df['sum_B']>0.95)]


    def findPopsWithData(self, genes, thresh=.95, minPopSize=None):
        d = self.df
        genes = ['sum_%s'%gene for gene in genes]

        if len(genes)==2:
            g1,g2 = genes
            self.d1=d[(d[g1] > thresh) & (d[g2] > thresh)]

        elif len(genes) == 3:
            g1,g2,g3 = genes
            self.d1 =d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh)]
        elif len(genes) == 4:
            g1,g2,g3,g4 = genes
            self.d1 =d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh) & (d[g4] > thresh)]
        elif len(genes) == 5:
            g1,g2,g3,g4,g5 = genes
            self.d1 =d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh) & (d[g4] > thresh) & (d[g5] > thresh)]
        elif len(genes) == 6:
            g1,g2,g3,g4,g5,g6 = genes
            self.d1 =d[(d[g1] > thresh) & (d[g2] > thresh) & (d[g3] > thresh) & (d[g4] > thresh) & (d[g5] > thresh) & (d[g6] > thresh)]
        
        if minPopSize:
            self.d1 = self.d1[self.d1.PopSize >= minPopSize]

    def makeAFdicts(self, genes):
        def makeDict(row):
            return {gene: dict(row.iloc[gc[gene][0]:gc[gene][1]]) for gene in genes}

        gc = dict(self.geneCols)
        for idx, row in self.d1.iterrows():
            popname = 'AFID_%s'%idx if (type(row.PopName) != str or len(row.PopName)<2) else row.PopName
            yield popname, makeDict(row)

    def reversePopIDlookup(self, popName, verbose=False):
        lookup = self.df[self.df['PopName'] == popName]
        if lookup.shape[0]:
            return str(lookup.iloc[0].PopName)
        elif verbose:
            print ("Warning - Lookup failed for %s" % popName)

    def parsePhylipDM(self, dmfile):
        firstLine = True
        rows = []
        currentRow = []
        popIds = []
        for line in open(dmfile):
            if firstLine:
                firstLine = False
            else:
                fields = line.split()
                try:
                    float(fields[0])
                    currentRow += list(map(float, fields))
                except ValueError:
                    popIds.append(fields[0].lstrip('P'))
                    if currentRow:
                        rows.append(currentRow)
                    currentRow = list(map(float, fields[1:]))
        rows.append(currentRow) ## assuming a row spans over several lines!!
        self.dm = pd.DataFrame(rows, index=popIds, columns=popIds)

    def findUniq(self, thresholdFct=np.median):
        dm = self.dm #parsePhylipDM(dmfile)
        dm1 = dm.where(dm>0) # ignore negative distance values
        closest = np.array([dm1[pop].drop([pop]).min() for pop in dm1.columns.values])
        threshold = thresholdFct(closest) ## matter of taste!
        self.uniq = [(int(pop), neighbor) for pop, neighbor in zip(dm1.columns.values, list(closest)) if neighbor > threshold]
        self.uniqDF = pd.DataFrame(self.uniq, columns=['Pop', 'DistanceToNN'])
        self.uniqDF.set_index('Pop', inplace=True)
        self.df = pd.concat([self.df, self.uniqDF], axis=1)
        print ("findUniq", self.df.shape)

    def inconsistentSubtypeAlleleFreqs(self):
        for afs in self.alleleFreqDicts:
            afs.alleleNamesToGraph()
            afs.checkSubtypes(())
        self.inconsistentPops = [afs.pop for afs in self.alleleFreqDicts if afs.inconsistencies]
        self.inconsistencyDF = pd.DataFrame([(int(afs.pop), len(afs.inconsistencies)) for afs in self.alleleFreqDicts], columns=['Pop','SubtypeConflicts'])
        self.inconsistencyDF.set_index('Pop', inplace=True)
        self.df = pd.concat([self.df, self.inconsistencyDF], axis=1)
        print ("inconsistentSubtypeAlleleFreqs", self.df.shape)

    def loadTree(self, tree, reroot=None):
        import dendropy
        self.t = dendropy.Tree.get_from_path(tree, schema='newick')
        ## Rerooting at e.g. Australian aboriginee population
        if reroot:
            yue = [nd for nd in self.t.leaf_node_iter() if reroot in nd.taxon.label][0]
            self.t.reroot_at_node(yue.parent_node)
    def suggestPopMerge(self):
        def cladePopIds(mnode):
            clade0 = [leaf.taxon.label for leaf in mnode.leaf_iter()]
            clade1 = [self.reversePopIDlookup(popName.split('/')[0],verbose=1) for popName in clade0]
            return [popId for popId in clade1 if popId and not popId in self.inconsistentPops]
        self.cladeDepth(self.t.seed_node)
        self.mergeNodes = self.shallowClades(self.t.seed_node)
        self.mergeClades = [cladePopIds(mnode) for mnode in self.mergeNodes]

    def cladeDepth(self, node):
        if node.is_leaf():
            node.depth = 0
            return 0
        cladeDepths = [edge.length + self.cladeDepth(edge.head_node) for edge in node.child_edges()]
        node.depth = max(cladeDepths)
        return node.depth

    def shallowClades(self, node, threshold=0.2):
        #if node.is_leaf():
        #    return []
        if node.depth < threshold:
            return [node]
        else:
            candidates = []
            for child in node.child_nodes():
                candidates += self.shallowClades(child)
            return candidates

    def finalStats(self):
        uniq = set(zip(*self.uniq)[0])
        smallPops = set(self.popInfo[self.popInfo['PopSize'] < self.smallPopThreshold]['0'])

        print ("A) Small Populations<%s" % self.smallPopThreshold, len(smallPops))
        print ("B) Pops with inconsistent subtypes:", len(self.inconsistentPops))
        #print "C) Overlap between A and B:", len(set(smallPops) & set(problemReport.keys()))
        #print "D) Small but unique (retained):", len(uniq & set(smallPops))
        #print "E) Total initial:", len(popList)
        #retain = set(popList) - ((self.smallPops - uniq) | set(problemReport.keys()))
    def sumAlleles(self):

        startcol = 0
        for gene, cols in self.groupings:
            self.df[gene] = self.df[self.df.columns[startcol:startcol + cols]].sum(axis=1)
            startcol += cols

    def filterSuitablePops(self, size=100, filterInconsistent=True, threshold=0.9, loci="ABC", keepUniq=False):
        # Now with one big Dataframe this can be simplified using &
        d = self.df

        selectedPops = set(self.df[self.df['PopSize'] >= size].index)
        if keepUniq: ## requires findUniq, which in turn requires DM to be parsed
            uniqPops = set([int(u) for u,d in self.uniq])
            selectedPops = selectedPops.union(uniqPops)

        filtPops = self.df[sorted(list(selectedPops))]

        if filterInconsistent:
            filtPops.drop(map(int, self.inconsistentPops), inplace=True)
        if loci == "ABC":
            filtPops = filtPops[(filtPops['A'] > threshold) & (filtPops['B'] > threshold) & (filtPops['C'] > threshold)]
        if loci == "AB":
            filtPops = filtPops[(filtPops['A'] > threshold) & (filtPops['B'] > threshold)]
        self.filtPops = filtPops

    def fixExceedingSum(self):
        startcol = 0
        for gene, col in self.groupings:
            needFixRows = self.df[self.df[gene] > 1]
            for idx, row in needFixRows.iterrows():
                v = row[startcol:startcol + col]
                if v.sum() > 0:
                    self.df.loc[idx, self.df.columns.values[startcol:startcol + col]] = v / v.sum()
                    self.df.loc[idx, gene] = 1
            startcol += col
    def selectPopsWsuffData(self, selectedLoci = ['A', 'B']):
        self.df = self.df[#(self.df.A > .95) & (self.df.B > .95) &\
                          (self.df.C > .95) & (self.df.PopSize>=99)]

    #def displayDM(df):
    #import pylab
    #pylab.matshow(dm)
    #pylab.show()
    def groupLoci(self):
        ## improved, was hackish which caused errors
        hlaGene = re.compile('([A-C])\d{1,3}') ## ideally be more precise and filter non-matches
        matches = [hlaGene.match(col) for col in self.df.columns.values]
        hlas = [match.group(1) for match in matches if match]
        self.groupings = [(gene, len(list(geneit))) for gene, geneit in groupby(hlas)]## another hack

    def phylipTable(self, filename, df, selLoci):
        ## http://evolution.genetics.washington.edu/phylip/doc/contchar.html
        w = open(filename, "w")
        #print ("%s %s" % (df.shape[0], len(selLoci)), file=w) ##nr of species and nr. of loci
        print (" ".join(["%s" % (alleles + 1) for (gene, alleles) in selLoci]), file=w) ## resp. total nr. of alleles per locus
        ## Warning!!! This needs a fix for selected Loci not starting from the beginning!
        cols = sum([lcol for locus, lcol in selLoci]) + len(selLoci) ## assuming the first 'cols' columns allele freqs
        for idx, row in df.iterrows(): ## Adding a prefix 'P'
            print ("P%-10s" % idx + " ".join(["%.5f" % val for val in row.values[:cols]]), file=w)
        w.close()
        print ("Wrote:", filename)
    def runPhylipGenDist(self, basename, selectedLoci=['A','B','C'], selectedPops=True, skipTableCreate=False):
        os.chdir("../GenDist")

        if not skipTableCreate:
            #self.groupLoci()
            ## ugly: assumed that selected Loci always starts from A,B...
            selectedLociCols = sum([cols for locus, cols in self.groupings if locus in selectedLoci])
            if selectedPops:
                df = self.df[(self.df.Selection=='X') & (self.df.C > .85)].iloc[:,:selectedLociCols] ## quick hack reg. C!!!
            else:
                df = self.df.iloc[:,:selectedLociCols] ## CHANGE!!!
            self.phylipTable("%s.csv" % basename, df, self.groupings[:len(selectedLoci)])


        with open("phylipCmdsNei.txt", "w") as phyl:
            print ("%s.csv" % (basename), file=phyl)
            print ("Y", file=phyl)

        print ("Calculating Nei Distance (using Phylip)")
        os.system("rm outfile outtree")  # F*cking Phylip I/O leads to so much rubbish
        os.system("%s/gendist < phylipCmdsNei.txt " % phylipDir)
        os.system("mv outfile %s.dm" % basename)
        os.chdir("../Scripts")
        self.basename = basename
    def runPhylipNeighbor(self):
        os.chdir("../GenDist")
        with open("phylipCmdsNeighbor.txt", "w") as phyl:
            print ("%s.dm" % self.basename, file=phyl)
            print ("Y", file=phyl)

        os.system("%s/neighbor < phylipCmdsNeighbor.txt" % phylipDir)
        os.chdir("../Scripts")

    def renamingPopulationsInTree(self):
        import dendropy
        os.chdir("../GenDist")
        t = dendropy.Tree.get_from_path("outtree", schema='newick')
        for nd in t.leaf_node_iter():
            #if not (0 <  int(nd.taxon.label[1:]) <= 25):
                #pdb.set_trace()
            #    label = str("%s/%d/" % tuple(self.df.loc[int(nd.taxon.label[1:]), ['PopName', 'PopSize']])) + nd.taxon.label[1:]
            #else: # no reliable PopSize for those from Yurek
            label = "%s" % self.df.loc[int(nd.taxon.label[1:]), 'PopName']
            #if '996' in str(nd.taxon.label):
            #    pdb.set_trace()
            nd.taxon.label = label.replace(" ", "_") ## looks nicer in iToL
        t.write_to_path("%s.nwk" % self.basename, schema="newick", unquoted_underscores=True)
        print ("Wrote %s.nwk" % self.basename)
        os.chdir("../Scripts")

    def geneticDistance(self, selectedLoci=['A', 'B']):
        from neiGeneticDistance import neiDF
        ## simple locus selection, assumes all from start til specified end
        colsplits = zip(*self.groupings[:len(selectedLoci)])[1]
        total = sum(colsplits)
        return neiDF(self.df.iloc[:,:total], colsplits[:-1])

if __name__ == "__main__1":
    ptree = PopulationTree()
    ptree.inconsistentSubtypeAlleleFreqs()
    ptree.df['SubtypeConflicts'].fillna(0, inplace=True)
    ptree.groupLoci()
    ptree.sumAlleles()
    #ptree.selectPopsWsuffData()
    #ptree.fixExceedingSum()
    #dm = ptree.geneticDistance(selectedLoci=['A', 'B', 'C']) ## my own implementation, not used
    #ptree.runPhylipGenDist('testneiC', selectedLoci=['C'], selectedPops=False)
    #ptree.runPhylipNeighbor()
    #ptree.renamingPopulationsInTree()

if __name__ == "__main__2":
    alutree = PopulationTree(precalc=True)
    alutree.runPhylipGenDist("gendist_alu1", skipTableCreate=True)
    alutree.runPhylipNeighbor()
if __name__ == "__main__": ## Dealing with hand selection, ABC
    ptree = PopulationTree("../Data/selAB95paki.csv", handSelection=True)
    #ptree.groupLoci()
    #ptree.runPhylipGenDist("selABC_95uae2a", selectedLoci=['A', 'B', 'C'])
    #ptree.runPhylipNeighbor()
    #ptree.renamingPopulationsInTree()
    ## ptree.loadTree(tree="../GenDist/selAB_95.nwk", reroot='Yuendumu')
if __name__ == "__main__0": ## preparing manual selection
    ptree = PopulationTree()
    ptree.inconsistentSubtypeAlleleFreqs()
    ptree.df['SubtypeConflicts'].fillna(0, inplace=True)

    ptree.groupLoci()
    ptree.sumAlleles()
    ptree.fixExceedingSum() ## SLOW!! WHY???
    ptree.parsePhylipDM("../GenDist/selComplete.dm")
    ptree.findUniq()

    d = ptree.df
    ## very lenient!
    selABC85 = d[((d.PopSize > 9) | (d.DistanceToNN > 0.2)) & ((d.SubtypeConflicts < 2) & (d.A > .85) & (d.A > .85) & (d.C > .85))].sort_values('PopName')

    # marking the previously hand selected 34 populations that had data for A B and C
    prevSelected = pd.read_csv("../Data/selAB95.csv", index_col=[0])
    selABC85 = pd.concat([selABC85, prevSelected[['Selection']]], axis=1).sort('PopName')
    #['PopName PopSize A B SubtypeConflicts DistanceToNN Selection'.split()]
    selABC85.to_csv("../Data/selABC95paki.csv")

    #ptree.loadTree(tree="../GenDist/selComplete.nwk", reroot='Yuendumu')
    #ptree.suggestPopMerge()
    #ptree.finalStats()
